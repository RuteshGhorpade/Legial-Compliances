# ğŸ§  Legial Compliances - AI-based Legal Document Classifier

This project is an AI-powered web application that classifies **legal documents** into categories (e.g., contracts, agreements) and generates a **summary** using NLP models.

It supports:
- ğŸ§¾ **OCR extraction** from PDF files using Tesseract
- ğŸ“Š **Document classification** using Logistic Regression & TF-IDF
- âœ‚ï¸ **Summarization** using Hugging Face's T5 model

---

## ğŸ“ Project Structure

```
Legial-Compliances/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ model/                  # Trained classifier & vectorizer
â”œâ”€â”€ data/
â”‚   â””â”€â”€ CONTRACT_TYPES/         # Training data (organized by folder)
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ uploads/                # Uploaded PDFs
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html              # Upload form
â”œâ”€â”€ app.py                      # Flask backend
â”œâ”€â”€ utils.py                    # OCR, summarization, classification
â”œâ”€â”€ train.py                    # Model training
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env                        # Tesseract & Poppler config
â””â”€â”€ README.md                   # You're here!
```

---

## âš™ï¸ Installation & Setup

### 1. Clone the Repo

```bash
git clone https://github.com/RuteshGhorpade/Legial-Compliances.git
cd Legial-Compliances
```

### 2. Create & Activate a Virtual Environment

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate
```

### 3. Install Python Dependencies

```bash
pip install -r requirements.txt
```

### 4. Install External Tools

- âœ… **[Tesseract OCR](https://github.com/tesseract-ocr/tesseract)**
- âœ… **[Poppler for PDF to Image conversion](http://blog.alivate.com.au/poppler-windows/)**

Make sure to add both to your system path, and update the `.env` file.

---

## ğŸ§ª Setup `.env` File

Create a `.env` file in the root directory:

```
POPPLER_PATH=C:\path\to\poppler\bin
```

Adjust path for your system.

---

## ğŸ‹ï¸â€â™‚ï¸ Train the Model (Optional)

To train or retrain the classifier on your own dataset:

```bash
python train.py
```

Your dataset should be placed inside the `data/CONTRACT_TYPES/` folder with this format:

```
data/
â””â”€â”€ CONTRACT_TYPES/
    â”œâ”€â”€ Employment/
    â”‚   â”œâ”€â”€ file1.txt
    â”‚   â”œâ”€â”€ file2.txt
    â””â”€â”€ Lease/
        â”œâ”€â”€ file1.txt
        â”œâ”€â”€ ...
```

---

## ğŸš€ Run the Web App

```bash
python app.py
```

Then open in your browser:  
ğŸ‘‰ http://localhost:5000

---

## ğŸ“¤ Upload a PDF

1. Select a PDF from the form.
2. Click **Upload**.
3. View:
   - Predicted document type
   - Match percentage
   - Top keywords
   - AI-generated summary

---

## ğŸ› ï¸ API Endpoints

### `/upload` [POST]
- Uploads a PDF and returns classification + summary.

### `/train` [POST]
- Triggers model training using the `data/CONTRACT_TYPES` folder.

---

## ğŸ§  Technologies Used

- **Flask** â€“ Backend API
- **Transformers (T5)** â€“ Text summarization
- **Scikit-learn** â€“ Text classification
- **pdf2image + pytesseract** â€“ OCR
- **TF-IDF Vectorizer** â€“ Feature extraction

---

## ğŸ§¾ Example Output

```json
{
  "document_type": "Employment",
  "match_percentage": 92.15,
  "keywords": ["employee", "agreement", "salary", ...],
  "summary": "This agreement outlines the conditions of employment between..."
}
```

---

## ğŸ“Œ To-Do / Improvements

- [ ] Frontend enhancements
- [ ] Docker support
- [ ] Deployment on Render/Heroku
- [ ] Add history tracking for uploaded documents

---

## ğŸ‘¨â€ğŸ’» Author

**Rutesh Pratap Ghorpade**  
ğŸ“« [LinkedIn](https://www.linkedin.com/in/ruteshghorpade)  
ğŸ”— GitHub: [@RuteshGhorpade](https://github.com/RuteshGhorpade)

---

## ğŸ“œ License

This project is licensed under the MIT License.


